{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Máquinas de aprendizaje: Tarea 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felipe Araya Barrera - 201173515-3  \n",
    "Sebastián Vergara Miranda - 201173515-3  \n",
    "9 de septiembre de 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Importaciones necesarias (secciones 1, 2 y 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> 1. Regresión Lineal Ordinaria (LSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Construcción de dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye un dataframe con los datos provistos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Luego, se realizan los siguientes ajustes sobre este:\n",
    "\n",
    "1. Se elimina columna sin nombre que especifica la posición de cada registro en el dataframe (línea 5). <br> <br>\n",
    "  \n",
    "2. Se almacena por separado la variable *train*, la cual indica si el registro pertenece o no\n",
    "al conjunto de entrenamiento (línea 6). <br> <br>\n",
    "\n",
    "3. Se crea un arreglo que realiza un cambio de notación para los valores que puede tomar\n",
    "la variable train, de tal manera que si posee el valor 'T', se cambia por **True**, mientras que si el valor es 'F' se cambia por **False** (línea 7). <br> <br>\n",
    "\n",
    "4. Se crea un arreglo en el que se indica si cada registro pertenece o no al conjunto de\n",
    "prueba (línea 8). <br> <br>\n",
    "\n",
    "5. Se elimina la variable train del dataframe creado (línea 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['Unnamed: 0'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bfda43cc3cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mistrain_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mistrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'T'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mistrain_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mistest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mistrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   1595\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1597\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1598\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1599\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   2568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2570\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels %s not contained in axis'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2571\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['Unnamed: 0'] not contained in axis"
     ]
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "df = df.drop('train',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Descripción de dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset se compone de 97 registros (pacientes), cada uno de los cuáles está descrito por\n",
    "9 variables, las que se detallan a continuación:\n",
    "\n",
    "1. *lcavol* : Logaritmo del volumen de cáncer presente. <br> <br>\n",
    "    \n",
    "2. *lweight*: Logaritmo del peso de la próstata. <br> <br> \n",
    "\n",
    "3. *age*: Edad. <br> <br>  \n",
    "\n",
    "4. *lbph*: Logaritmo de la cantidad de hiperplasia benigna de próstata. <br> <br> \n",
    "\n",
    "5. *svi*: Indica si existe invasión de la vesícula seminal o no. <br> <br> \n",
    "\n",
    "6. *lcp*: Logaritmo de la penetración capsular. <br> <br>\n",
    "\n",
    "7. *gleason*: Medida del grado de agresividad del cáncer, en base a la escala de Gleason. <br> <br>  \n",
    "\n",
    "8. *pgg45* : Porcentaje que representa la presencia de los patrones de Gleason 4 y 5. <br> <br>  \n",
    "\n",
    "9. *lpsa*: Logaritmo del nivel de antígeno prostático específico (PSA). <br> <br>\n",
    "Además, no existen valores nulos para ningún registro. Más información acerca del dataset (principalmente estadística) puede encontrarse al ejecutar los siguientes comandos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
       "0            1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
       "1            2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
       "2            3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
       "3            4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6   \n",
       "4            5  0.751416  3.432373   62 -1.386294    0 -1.386294        6   \n",
       "5            6 -1.049822  3.228826   50 -1.386294    0 -1.386294        6   \n",
       "6            7  0.737164  3.473518   64  0.615186    0 -1.386294        6   \n",
       "7            8  0.693147  3.539509   58  1.536867    0 -1.386294        6   \n",
       "8            9 -0.776529  3.539509   47 -1.386294    0 -1.386294        6   \n",
       "9           10  0.223144  3.244544   63 -1.386294    0 -1.386294        6   \n",
       "10          11  0.254642  3.604138   65 -1.386294    0 -1.386294        6   \n",
       "11          12 -1.347074  3.598681   63  1.266948    0 -1.386294        6   \n",
       "12          13  1.613430  3.022861   63 -1.386294    0 -0.597837        7   \n",
       "13          14  1.477049  2.998229   67 -1.386294    0 -1.386294        7   \n",
       "14          15  1.205971  3.442019   57 -1.386294    0 -0.430783        7   \n",
       "15          16  1.541159  3.061052   66 -1.386294    0 -1.386294        6   \n",
       "16          17 -0.415515  3.516013   70  1.244155    0 -0.597837        7   \n",
       "17          18  2.288486  3.649359   66 -1.386294    0  0.371564        6   \n",
       "18          19 -0.562119  3.267666   41 -1.386294    0 -1.386294        6   \n",
       "19          20  0.182322  3.825375   70  1.658228    0 -1.386294        6   \n",
       "20          21  1.147402  3.419365   59 -1.386294    0 -1.386294        6   \n",
       "21          22  2.059239  3.501043   60  1.474763    0  1.348073        7   \n",
       "22          23 -0.544727  3.375880   59 -0.798508    0 -1.386294        6   \n",
       "23          24  1.781709  3.451574   63  0.438255    0  1.178655        7   \n",
       "24          25  0.385262  3.667400   69  1.599388    0 -1.386294        6   \n",
       "25          26  1.446919  3.124565   68  0.300105    0 -1.386294        6   \n",
       "26          27  0.512824  3.719651   65 -1.386294    0 -0.798508        7   \n",
       "27          28 -0.400478  3.865979   67  1.816452    0 -1.386294        7   \n",
       "28          29  1.040277  3.128951   67  0.223144    0  0.048790        7   \n",
       "29          30  2.409644  3.375880   65 -1.386294    0  1.619388        6   \n",
       "..         ...       ...       ...  ...       ...  ...       ...      ...   \n",
       "67          68  2.198335  4.050915   72  2.307573    0 -0.430783        7   \n",
       "68          69 -0.446287  4.408547   69 -1.386294    0 -1.386294        6   \n",
       "69          70  1.193922  4.780383   72  2.326302    0 -0.798508        7   \n",
       "70          71  1.864080  3.593194   60 -1.386294    1  1.321756        7   \n",
       "71          72  1.160021  3.341093   77  1.749200    0 -1.386294        7   \n",
       "72          73  1.214913  3.825375   69 -1.386294    1  0.223144        7   \n",
       "73          74  1.838961  3.236716   60  0.438255    1  1.178655        9   \n",
       "74          75  2.999226  3.849083   69 -1.386294    1  1.909542        7   \n",
       "75          76  3.141130  3.263849   68 -0.051293    1  2.420368        7   \n",
       "76          77  2.010895  4.433789   72  2.122262    0  0.500775        7   \n",
       "77          78  2.537657  4.354784   78  2.326302    0 -1.386294        7   \n",
       "78          79  2.648300  3.582129   69 -1.386294    1  2.583998        7   \n",
       "79          80  2.779440  3.823192   63 -1.386294    0  0.371564        7   \n",
       "80          81  1.467874  3.070376   66  0.559616    0  0.223144        7   \n",
       "81          82  2.513656  3.473518   57  0.438255    0  2.327278        7   \n",
       "82          83  2.613007  3.888754   77 -0.527633    1  0.559616        7   \n",
       "83          84  2.677591  3.838376   65  1.115142    0  1.749200        9   \n",
       "84          85  1.562346  3.709907   60  1.695616    0  0.810930        7   \n",
       "85          86  3.302849  3.518980   64 -1.386294    1  2.327278        7   \n",
       "86          87  2.024193  3.731699   58  1.638997    0 -1.386294        6   \n",
       "87          88  1.731656  3.369018   62 -1.386294    1  0.300105        7   \n",
       "88          89  2.807594  4.718052   65 -1.386294    1  2.463853        7   \n",
       "89          90  1.562346  3.695110   76  0.936093    1  0.810930        7   \n",
       "90          91  3.246491  4.101817   68 -1.386294    0 -1.386294        6   \n",
       "91          92  2.532903  3.677566   61  1.348073    1 -1.386294        7   \n",
       "92          93  2.830268  3.876396   68 -1.386294    1  1.321756        7   \n",
       "93          94  3.821004  3.896909   44 -1.386294    1  2.169054        7   \n",
       "94          95  2.907447  3.396185   52 -1.386294    1  2.463853        7   \n",
       "95          96  2.882564  3.773910   68  1.558145    1  1.558145        7   \n",
       "96          97  3.471966  3.974998   68  0.438255    1  2.904165        7   \n",
       "\n",
       "    pgg45      lpsa train  \n",
       "0       0 -0.430783     T  \n",
       "1       0 -0.162519     T  \n",
       "2      20 -0.162519     T  \n",
       "3       0 -0.162519     T  \n",
       "4       0  0.371564     T  \n",
       "5       0  0.765468     T  \n",
       "6       0  0.765468     F  \n",
       "7       0  0.854415     T  \n",
       "8       0  1.047319     F  \n",
       "9       0  1.047319     F  \n",
       "10      0  1.266948     T  \n",
       "11      0  1.266948     T  \n",
       "12     30  1.266948     T  \n",
       "13      5  1.348073     T  \n",
       "14      5  1.398717     F  \n",
       "15      0  1.446919     T  \n",
       "16     30  1.470176     T  \n",
       "17      0  1.492904     T  \n",
       "18      0  1.558145     T  \n",
       "19      0  1.599388     T  \n",
       "20      0  1.638997     T  \n",
       "21     20  1.658228     F  \n",
       "22      0  1.695616     T  \n",
       "23     60  1.713798     T  \n",
       "24      0  1.731656     F  \n",
       "25      0  1.766442     F  \n",
       "26     70  1.800058     T  \n",
       "27     20  1.816452     F  \n",
       "28     80  1.848455     T  \n",
       "29      0  1.894617     T  \n",
       "..    ...       ...   ...  \n",
       "67     10  2.962692     T  \n",
       "68      0  2.962692     T  \n",
       "69      5  2.972975     T  \n",
       "70     60  3.013081     T  \n",
       "71     25  3.037354     T  \n",
       "72     20  3.056357     F  \n",
       "73     90  3.075006     F  \n",
       "74     20  3.275256     T  \n",
       "75     50  3.337547     T  \n",
       "76     60  3.392829     T  \n",
       "77     10  3.435599     T  \n",
       "78     70  3.457893     T  \n",
       "79     50  3.513037     F  \n",
       "80     40  3.516013     T  \n",
       "81     60  3.530763     T  \n",
       "82     30  3.565298     T  \n",
       "83     70  3.570940     F  \n",
       "84     30  3.587677     T  \n",
       "85     60  3.630986     T  \n",
       "86      0  3.680091     T  \n",
       "87     30  3.712352     T  \n",
       "88     60  3.984344     T  \n",
       "89     75  3.993603     T  \n",
       "90      0  4.029806     T  \n",
       "91     15  4.129551     T  \n",
       "92     60  4.385147     T  \n",
       "93     40  4.684443     T  \n",
       "94     10  5.143124     F  \n",
       "95     80  5.477509     T  \n",
       "96     20  5.582932     F  \n",
       "\n",
       "[97 rows x 11 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.145456</td>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     lcavol    lweight        age       lbph        svi  \\\n",
       "count   97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    49.000000   1.350010   3.628943  63.865979   0.100356   0.216495   \n",
       "std     28.145456   1.178625   0.428411   7.445117   1.450807   0.413995   \n",
       "min      1.000000  -1.347074   2.374906  41.000000  -1.386294   0.000000   \n",
       "25%     25.000000   0.512824   3.375880  60.000000  -1.386294   0.000000   \n",
       "50%     49.000000   1.446919   3.623007  65.000000   0.300105   0.000000   \n",
       "75%     73.000000   2.127041   3.876396  68.000000   1.558145   0.000000   \n",
       "max     97.000000   3.821004   4.780383  79.000000   2.326302   1.000000   \n",
       "\n",
       "             lcp    gleason       pgg45       lpsa  \n",
       "count  97.000000  97.000000   97.000000  97.000000  \n",
       "mean   -0.179366   6.752577   24.381443   2.478387  \n",
       "std     1.398250   0.722134   28.204035   1.154329  \n",
       "min    -1.386294   6.000000    0.000000  -0.430783  \n",
       "25%    -1.386294   6.000000    0.000000   1.731656  \n",
       "50%    -0.798508   7.000000   15.000000   2.591516  \n",
       "75%     1.178655   7.000000   40.000000   3.056357  \n",
       "max     2.904165   9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Normalización de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de llevar la construcción de un modelo predictivo, es necesario normalizar los datos,\n",
    "pues se está trabajando con variables medidas en unidades y escalas diferentes. Al normalizar,\n",
    "es posible realizar comparaciones razonables entre ellas. Así, cada variable numérica se escala\n",
    "en el rango [0,1]. Para esta instancia en particular, los valores de *lpsa* se mantienen respecto al dataset original. También, se observa que la media de cada variable tiende a 0 y la varianza es muy cercana a 1. Para la normalización, se lleva a cabo el siguiente procedimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['lpsa'] = df['lpsa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Construcción de modelo de regresión lineal ordinaria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar el modelo, se ejecutan los siguientes pasos: <br> \n",
    "1. Primero, se separa el conjunto de datos en dos partes: La primera contiene solo las\n",
    "variables predictivas ($C_1$), mientras que la segunda, sólo la variable a predecir ($C_2$).<br> <br> \n",
    "2. En $C_1$ , se agrega una nueva variable, que representa el intercepto que será utilizado por\n",
    "cada registro para construir el modelo de regresión. <br> <br>\n",
    "3. Tanto $C_1$ como $C_2$ se subdividen en un conjunto que contiene registros que pertenecen\n",
    "al set de entrenamiento ($C_{11}$ y $C_{21}$) y en otro que agrupa los que pertenecen al set de prueba ($C_{21}$ y $C_{22}$ ). <br> <br>\n",
    "4. Finalmente, para implementar la regresión lineal, se entrega a la función correspondiente\n",
    "los conjuntos $C_{11}$ y $C_{21}$ como argumentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_scaled.ix[: , :-1]\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['lpsa']\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 Pesos y Z-score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen los pesos, errores estándar y Z-score para cada variable del\n",
    "modelo elaborado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pesos\n",
    "weights = linreg.coef_\n",
    "#Error estandar\n",
    "SEM = np.asarray(Xtrain.std()) / np.sqrt(len(Xtrain))\n",
    "#A partir de lo anterior, se calculan los Z-score de cada variable\n",
    "Z_score = weights / SEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla 1 resume los valores obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <table style=\"width:100%\">\n",
    " <caption>Tabla 1: Peso, SEM y Z-score de cada variable del modelo LSS.</caption>\n",
    "  <tr>\n",
    "    <th>**Variable**</th>\n",
    "    <th>**Peso**</th>\n",
    "    <th>**Error Estándar (SEM)**</th>\n",
    "    <th>**Z-score**</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lcavol*</td>\n",
    "    <td>0.68</td>\n",
    "    <td>0.13</td>\n",
    "    <td>5.22</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lweight*</td>\n",
    "    <td>0.26</td>\n",
    "    <td>0.14</td>\n",
    "    <td>1.92</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lcavol*</td>\n",
    "    <td>-0.14</td>\n",
    "    <td>0.12</td>\n",
    "    <td>-1.14</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lbph*</td>\n",
    "    <td>0.21</td>\n",
    "    <td>0.12</td>\n",
    "    <td>1.69</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*svi*</td>\n",
    "    <td>0.30</td>\n",
    "    <td>0.12</td>\n",
    "    <td>2.44</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lcp*</td>\n",
    "    <td>-0.29</td>\n",
    "    <td>0.12</td>\n",
    "    <td>-2.33</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*gleason*</td>\n",
    "    <td>-0.02</td>\n",
    "    <td>0.12</td>\n",
    "    <td>-0.18</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*pgg45*</td>\n",
    "    <td>0.27</td>\n",
    "    <td>0.13</td>\n",
    "    <td>2.08</td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a estos resultados, las variables que presentan una mayor correlación con la\n",
    "variable a predecir son *lcavol*, *svi* y *lcp*. Si se utiliza un nivel de significancia del 5 %, entonces existe evidencia suficiente para afirmar que la variable **NO** presenta una fuerte relación con la respuesta si Z-score ∈ [-1.668, 1.668]. Ante esto, existe evidencia suficiente para afirmar que las variables *age* y *gleason* no están relacionadas con la variable a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6 Estimación de error de predicción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente, se calcula el error real del modelo (error cuadrático medio), obteniéndose\n",
    "MSE = 0.52."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521274005508\n"
     ]
    }
   ],
   "source": [
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "print mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se evalúan los resultados obtenidos por medio del método cross validation.\n",
    "Se estudian dos casos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caso 1**: K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956514631616\n"
     ]
    }
   ],
   "source": [
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "k_fold1 = cross_validation.KFold(len(Xm), 5)\n",
    "mse_cv1 = 0\n",
    "for k, (train, val) in enumerate(k_fold1):\n",
    "  linreg = lm.LinearRegression(fit_intercept = False)\n",
    "  linreg.fit(Xm[train], ym[train])\n",
    "  yhat_val = linreg.predict(Xm[val])\n",
    "  mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "  mse_cv1 += mse_fold\n",
    "mse_cv1 = mse_cv1 / 5\n",
    "print mse_cv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, para K = 5, se obtiene un error $e_1$ = 0.96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caso 2**: K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757237472963\n"
     ]
    }
   ],
   "source": [
    "k_fold2 = cross_validation.KFold(len(Xm), 10)\n",
    "mse_cv2 = 0\n",
    "for k, (train, val) in enumerate(k_fold2):\n",
    "  linreg = lm.LinearRegression(fit_intercept = False)\n",
    "  linreg.fit(Xm[train], ym[train])\n",
    "  yhat_val = linreg.predict(Xm[val])\n",
    "  mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "  mse_cv2 += mse_fold\n",
    "mse_cv2 = mse_cv2 / 10\n",
    "print mse_cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, con K = 10, se obtiene un error $e_2$ = 0.76. <br>\n",
    "\n",
    "Se observa que para los casos 1 y 2, el error es considerablemente mayor respecto a MSE.\n",
    "Esto quiere decir que existe un alto nivel de dependencia del modelo respecto a los datos\n",
    "usados para construirlo. En otras palabras, el modelo está sobre ajustado (*overfitting*), por\n",
    "lo que entregará buenas predicciones para los casos pertenecientes al dataset original, pero\n",
    "no será el más apropiado si se desea predecir el valor de la variable de interés para casos de\n",
    "pacientes que no se encuentran dentro del conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7 Error de predicción por dato**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estudia la validez de suponer que los errores de predicción sobre los datos de entrenamiento siguen una distribución normal. Con la ejecución del siguiente código, se obtiene un gráfico que muestra el comportamiento de los errores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se estima error de prediccion por cada dato de entrenamiento\n",
    "yhat_train = linreg.predict(Xtrain)\n",
    "ytrain_array = np.asarray(ytrain)\n",
    "error = yhat_train - ytrain_array\n",
    "#Se genera grafico de errores\n",
    "stats.probplot(error, dist='norm', plot=plt)\n",
    "plt.title('Siguen los errores de prediccion sobre el conjunto de entrenamiento una distribucion normal?')\n",
    "plt.ylabel('Error dato de entrenamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el conjunto de errores puede representarse mediante una recta, idea que\n",
    "se reafirma al notar que el coeficiente de correlación es $R^2$ = 0,9913. Como consecuencia de\n",
    "lo anterior, y de acuerdo con el marco teórico, es correcto señalar que los errores siguen una\n",
    "distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selección vía FSS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa *Forward Step-wise Selection* (FSS). Para agregar una variable al modelo, se utiliza como criterio el mínimo MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "  mse_train = []\n",
    "  p = x.shape[1]-1\n",
    "  k = min(p, k)\n",
    "  names_x = np.array(names_x)\n",
    "  remaining = range(0, p)\n",
    "  selected = [p]\n",
    "  current_score = 0.0\n",
    "  best_new_score = 0.0\n",
    "  while [remaining] and len(selected)<=k :\n",
    "    score_candidates = []\n",
    "    for candidate in remaining:\n",
    "      model = lm.LinearRegression(fit_intercept=False)\n",
    "      indexes = selected + [candidate]\n",
    "      x_train = x[:,indexes]\n",
    "      predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "      residuals_train = predictions_train - y\n",
    "      mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "      score_candidates.append((mse_candidate, candidate))\n",
    "    score_candidates.sort()\n",
    "    score_candidates[:] = score_candidates[::-1]\n",
    "    best_new_score, best_candidate = score_candidates.pop()\n",
    "    remaining.remove(best_candidate)\n",
    "    selected.append(best_candidate)\n",
    "    print \"selected = %s ...\"%(names_x[best_candidate])\n",
    "    print \"total variables = %d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    mse_train.append(best_new_score)\n",
    "  return selected, mse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se aplica la función creada sobre los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSS, error de entrenamiento:\n",
      "selected = Lcavol ...\n",
      "total variables = 2, mse = 0.664606\n",
      "selected = Lweight ...\n",
      "total variables = 3, mse = 0.553610\n",
      "selected = Svi ...\n",
      "total variables = 4, mse = 0.521011\n",
      "selected = Lbph ...\n",
      "total variables = 5, mse = 0.489776\n",
      "selected = Pgg45 ...\n",
      "total variables = 6, mse = 0.478648\n",
      "selected = Lcp ...\n",
      "total variables = 7, mse = 0.455818\n",
      "selected = Age ...\n",
      "total variables = 8, mse = 0.439363\n",
      "selected = Gleason ...\n",
      "total variables = 9, mse = 0.439200\n"
     ]
    }
   ],
   "source": [
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "print \"FSS, error de entrenamiento:\"\n",
    "seleccionados, mse_train = fss(Xm,ym,names_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al mismo tiempo, se modifica la función anterior para aplicar FSS sobre los datos de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xm_test = Xtest.as_matrix()\n",
    "ym_test = ytest.as_matrix()\n",
    "\n",
    "def fss_test(x,x_t, y, y_t, selected, names_x):\n",
    "  score = []\n",
    "  indexes = []\n",
    "  indexes.append(selected[0])\n",
    "  for i in range(1, len(selected)):\n",
    "    model = lm.LinearRegression(fit_intercept=False)\n",
    "    indexes.append(selected[i])\n",
    "    x_train = x[:,indexes]\n",
    "    x_test = x_t[:,indexes]\n",
    "    prediction_test = model.fit(x_train, y).predict(x_test)\n",
    "    residuals_test = prediction_test - y_t\n",
    "    mse_test = np.mean(np.power(residuals_test,2))\n",
    "    score.append(mse_test)\n",
    "  return score\n",
    "\n",
    "mse_test = fss_test(Xm,Xm_test,ym,ym_test,seleccionados,names_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se construye un gráfico con el error de entrenamiento y de pruebas en función de la cantidad de variables. Es pertinente señalar que FSS parte incluyendo el intercepto y luego empieza a agregar variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_predictores = range(1, Xm.shape[1])\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.plot(n_predictores, mse_train, 'bo-', label='FSS train')\n",
    "ax.plot(n_predictores, mse_test, 'ro-', label='FSS test')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Cantidad de variables')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Step-wise Selection (FSS)')\n",
    "\n",
    "plt.axis([0, 9, 0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo al gráfico obtenido anteriormente, se observa que el error de entrenamiento decrece a medida que aumenta la cantidad de variables del modelo. Por otro lado, el error de prueba decrece al principio, pero después aumenta, lo que implica que el modelo está sobreajustado. Además, se puede ver que el error es mínimo cuando existen tres variables en el modelo. Dichas variables son: *Lcavol*, *Lweight* y *Svi*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selección vía FSS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa *Backward Step-wise Selection* (BSS). Para eliminar una variable, se utiliza mínimo MSE como criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bss(x, y, names_x):\n",
    "  mse_train = []\n",
    "  orden_drop = []\n",
    "  names_x = np.array(names_x)\n",
    "  remaining = range(0, x.shape[1])\n",
    "  selected = range(0,x.shape[1])\n",
    "\n",
    "  model = lm.LinearRegression(fit_intercept=False)\n",
    "  predictions_train = model.fit(x, y).predict(x)\n",
    "  residuals_train = predictions_train - y\n",
    "  mse_train.append(np.mean(np.power(residuals_train, 2)))\n",
    "\n",
    "  while (len(selected) != 1):\n",
    "    score_candidates = []\n",
    "    for candidate in remaining:\n",
    "      model = lm.LinearRegression(fit_intercept=False)\n",
    "      selected.remove(candidate)\n",
    "      indexes = selected\n",
    "      x_train = x[:,indexes]\n",
    "      predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "      residuals_train = predictions_train - y\n",
    "      mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "      score_candidates.append((mse_candidate, candidate))\n",
    "      selected.append(candidate)\n",
    "    score_candidates.sort()\n",
    "    score_candidates[:] = score_candidates[::-1]\n",
    "    worst_new_score, worst_candidate = score_candidates.pop()\n",
    "    remaining.remove(worst_candidate)\n",
    "    selected.remove(worst_candidate)\n",
    "    print \"selected = %s ...\"%(names_x[worst_candidate])\n",
    "    print \"total variables = %d, mse = %f\"%(len(indexes),worst_new_score)\n",
    "    mse_train.append(worst_new_score)\n",
    "    orden_drop.append(worst_candidate)\n",
    "  orden_drop.append(x.shape[1]-1)\n",
    "\n",
    "  return orden_drop, mse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se aplica la función creada sobre los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSS, error de entrenamiento:\n",
      "selected = Gleason ...\n",
      "total variables = 8, mse = 0.439363\n",
      "selected = Age ...\n",
      "total variables = 7, mse = 0.455818\n",
      "selected = Lcp ...\n",
      "total variables = 6, mse = 0.478648\n",
      "selected = Pgg45 ...\n",
      "total variables = 5, mse = 0.489776\n",
      "selected = Lbph ...\n",
      "total variables = 4, mse = 0.521011\n",
      "selected = Svi ...\n",
      "total variables = 3, mse = 0.553610\n",
      "selected = Lweight ...\n",
      "total variables = 2, mse = 0.664606\n",
      "selected = Lcavol ...\n",
      "total variables = 1, mse = 1.437036\n"
     ]
    }
   ],
   "source": [
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\", \"intercept\"]\n",
    "print \"BSS, error de entrenamiento:\"\n",
    "seleccionados, mse_train  = bss(Xm,ym,names_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se modifica la función anterior para aplicar BSS sobre los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bss_test(x,x_t, y, y_t, selected, names_x):\n",
    "  score = []\n",
    "  indexes = selected[:]\n",
    "  for i in selected:\n",
    "    model = lm.LinearRegression(fit_intercept=False)\n",
    "    x_train = x[:,indexes]\n",
    "    x_test = x_t[:,indexes]\n",
    "    prediction_test = model.fit(x_train, y).predict(x_test)\n",
    "    residuals_test = prediction_test - y_t\n",
    "    mse_test = np.mean(np.power(residuals_test,2))\n",
    "    score.append(mse_test)\n",
    "    indexes.remove(i)\n",
    "\n",
    "  return score\n",
    "\n",
    "mse_test = bss_test(Xm,Xm_test,ym,ym_test,seleccionados,names_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se construye un gráfico con el error de entrenamiento y de pruebas de acuerdo al número de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_predictores = range(0, Xm.shape[1])\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "ax.plot(n_predictores, mse_train, 'bo-', label='BSS train')\n",
    "ax.plot(n_predictores, mse_test, 'ro-', label='BSS test')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Cantidad de variables')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Backward Step-wise Selection (BSS)')\n",
    "plt.legend(loc=2)\n",
    "plt.axis([0, 9, 0, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver en el gráfico construído que el error de entrenamiento es menor mientras menos variables tiene el modelo, tal y como debiese ocurrir según la teoría. Por otro lado, el error de prueba decrece al comienzo, pero luego de que la cantidad de variables ha disminuído demasiado, el error aumenta, puesto que no se cuenta con una cantidad apropiada de variables para elaborar un buen modelo. Además, el error mínimo de prueba se obtiene al eliminar cinco variables. Así, se cuenta con un modelo que posee las variables *Lcavol*, *Lweight* y *Svi*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
