{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Máquinas de aprendizaje: Tarea 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felipe Araya Barrera - 201173515-3  \n",
    "Sebastián Vergara Miranda - 201173515-3  \n",
    "9 de septiembre de 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Importaciones necesarias (secciones 1, 2 y 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> 1. Regresión Lineal Ordinaria (LSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Construcción de dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye un dataframe con los datos provistos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Luego, se realizan los siguientes ajustes sobre este:\n",
    "\n",
    "1. Se elimina columna sin nombre que especifica la posición de cada registro en el dataframe (línea 5). <br> <br>\n",
    "  \n",
    "2. Se almacena por separado la variable *train*, la cual indica si el registro pertenece o no\n",
    "al conjunto de entrenamiento (línea 6). <br> <br>\n",
    "\n",
    "3. Se crea un arreglo que realiza un cambio de notación para los valores que puede tomar\n",
    "la variable train, de tal manera que si posee el valor 'T', se cambia por **True**, mientras que si el valor es 'F' se cambia por **False** (línea 7). <br> <br>\n",
    "\n",
    "4. Se crea un arreglo en el que se indica si cada registro pertenece o no al conjunto de\n",
    "prueba (línea 8). <br> <br>\n",
    "\n",
    "5. Se elimina la variable train del dataframe creado (línea 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "df = df.drop('train',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Descripción de dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset se compone de 97 registros (pacientes), cada uno de los cuáles está descrito por\n",
    "9 variables, las que se detallan a continuación:\n",
    "\n",
    "1. *lcavol* : Logaritmo del volumen de cáncer presente. <br> <br>\n",
    "    \n",
    "2. *lweight*: Logaritmo del peso de la próstata. <br> <br> \n",
    "\n",
    "3. *age*: Edad. <br> <br>  \n",
    "\n",
    "4. *lbph*: Logaritmo de la cantidad de hiperplasia benigna de próstata. <br> <br> \n",
    "\n",
    "5. *svi*: Indica si existe invasión de la vesícula seminal o no. <br> <br> \n",
    "\n",
    "6. *lcp*: Logaritmo de la penetración capsular. <br> <br>\n",
    "\n",
    "7. *gleason*: Medida del grado de agresividad del cáncer, en base a la escala de Gleason. <br> <br>  \n",
    "\n",
    "8. *pgg45* : Porcentaje que representa la presencia de los patrones de Gleason 4 y 5. <br> <br>  \n",
    "\n",
    "9. *lpsa*: Logaritmo del nivel de antígeno prostático específico (PSA). <br> <br>\n",
    "Además, no existen valores nulos para ningún registro. Más información acerca del dataset (principalmente estadística) puede encontrarse al ejecutar los siguientes comandos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     Unnamed: 0    lcavol   lweight  age      lbph  svi       lcp  gleason  \\\n",
       "0            1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6   \n",
       "1            2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6   \n",
       "2            3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7   \n",
       "3            4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6   \n",
       "4            5  0.751416  3.432373   62 -1.386294    0 -1.386294        6   \n",
       "5            6 -1.049822  3.228826   50 -1.386294    0 -1.386294        6   \n",
       "6            7  0.737164  3.473518   64  0.615186    0 -1.386294        6   \n",
       "7            8  0.693147  3.539509   58  1.536867    0 -1.386294        6   \n",
       "8            9 -0.776529  3.539509   47 -1.386294    0 -1.386294        6   \n",
       "9           10  0.223144  3.244544   63 -1.386294    0 -1.386294        6   \n",
       "10          11  0.254642  3.604138   65 -1.386294    0 -1.386294        6   \n",
       "11          12 -1.347074  3.598681   63  1.266948    0 -1.386294        6   \n",
       "12          13  1.613430  3.022861   63 -1.386294    0 -0.597837        7   \n",
       "13          14  1.477049  2.998229   67 -1.386294    0 -1.386294        7   \n",
       "14          15  1.205971  3.442019   57 -1.386294    0 -0.430783        7   \n",
       "15          16  1.541159  3.061052   66 -1.386294    0 -1.386294        6   \n",
       "16          17 -0.415515  3.516013   70  1.244155    0 -0.597837        7   \n",
       "17          18  2.288486  3.649359   66 -1.386294    0  0.371564        6   \n",
       "18          19 -0.562119  3.267666   41 -1.386294    0 -1.386294        6   \n",
       "19          20  0.182322  3.825375   70  1.658228    0 -1.386294        6   \n",
       "20          21  1.147402  3.419365   59 -1.386294    0 -1.386294        6   \n",
       "21          22  2.059239  3.501043   60  1.474763    0  1.348073        7   \n",
       "22          23 -0.544727  3.375880   59 -0.798508    0 -1.386294        6   \n",
       "23          24  1.781709  3.451574   63  0.438255    0  1.178655        7   \n",
       "24          25  0.385262  3.667400   69  1.599388    0 -1.386294        6   \n",
       "25          26  1.446919  3.124565   68  0.300105    0 -1.386294        6   \n",
       "26          27  0.512824  3.719651   65 -1.386294    0 -0.798508        7   \n",
       "27          28 -0.400478  3.865979   67  1.816452    0 -1.386294        7   \n",
       "28          29  1.040277  3.128951   67  0.223144    0  0.048790        7   \n",
       "29          30  2.409644  3.375880   65 -1.386294    0  1.619388        6   \n",
       "..         ...       ...       ...  ...       ...  ...       ...      ...   \n",
       "67          68  2.198335  4.050915   72  2.307573    0 -0.430783        7   \n",
       "68          69 -0.446287  4.408547   69 -1.386294    0 -1.386294        6   \n",
       "69          70  1.193922  4.780383   72  2.326302    0 -0.798508        7   \n",
       "70          71  1.864080  3.593194   60 -1.386294    1  1.321756        7   \n",
       "71          72  1.160021  3.341093   77  1.749200    0 -1.386294        7   \n",
       "72          73  1.214913  3.825375   69 -1.386294    1  0.223144        7   \n",
       "73          74  1.838961  3.236716   60  0.438255    1  1.178655        9   \n",
       "74          75  2.999226  3.849083   69 -1.386294    1  1.909542        7   \n",
       "75          76  3.141130  3.263849   68 -0.051293    1  2.420368        7   \n",
       "76          77  2.010895  4.433789   72  2.122262    0  0.500775        7   \n",
       "77          78  2.537657  4.354784   78  2.326302    0 -1.386294        7   \n",
       "78          79  2.648300  3.582129   69 -1.386294    1  2.583998        7   \n",
       "79          80  2.779440  3.823192   63 -1.386294    0  0.371564        7   \n",
       "80          81  1.467874  3.070376   66  0.559616    0  0.223144        7   \n",
       "81          82  2.513656  3.473518   57  0.438255    0  2.327278        7   \n",
       "82          83  2.613007  3.888754   77 -0.527633    1  0.559616        7   \n",
       "83          84  2.677591  3.838376   65  1.115142    0  1.749200        9   \n",
       "84          85  1.562346  3.709907   60  1.695616    0  0.810930        7   \n",
       "85          86  3.302849  3.518980   64 -1.386294    1  2.327278        7   \n",
       "86          87  2.024193  3.731699   58  1.638997    0 -1.386294        6   \n",
       "87          88  1.731656  3.369018   62 -1.386294    1  0.300105        7   \n",
       "88          89  2.807594  4.718052   65 -1.386294    1  2.463853        7   \n",
       "89          90  1.562346  3.695110   76  0.936093    1  0.810930        7   \n",
       "90          91  3.246491  4.101817   68 -1.386294    0 -1.386294        6   \n",
       "91          92  2.532903  3.677566   61  1.348073    1 -1.386294        7   \n",
       "92          93  2.830268  3.876396   68 -1.386294    1  1.321756        7   \n",
       "93          94  3.821004  3.896909   44 -1.386294    1  2.169054        7   \n",
       "94          95  2.907447  3.396185   52 -1.386294    1  2.463853        7   \n",
       "95          96  2.882564  3.773910   68  1.558145    1  1.558145        7   \n",
       "96          97  3.471966  3.974998   68  0.438255    1  2.904165        7   \n",
       "\n",
       "    pgg45      lpsa train  \n",
       "0       0 -0.430783     T  \n",
       "1       0 -0.162519     T  \n",
       "2      20 -0.162519     T  \n",
       "3       0 -0.162519     T  \n",
       "4       0  0.371564     T  \n",
       "5       0  0.765468     T  \n",
       "6       0  0.765468     F  \n",
       "7       0  0.854415     T  \n",
       "8       0  1.047319     F  \n",
       "9       0  1.047319     F  \n",
       "10      0  1.266948     T  \n",
       "11      0  1.266948     T  \n",
       "12     30  1.266948     T  \n",
       "13      5  1.348073     T  \n",
       "14      5  1.398717     F  \n",
       "15      0  1.446919     T  \n",
       "16     30  1.470176     T  \n",
       "17      0  1.492904     T  \n",
       "18      0  1.558145     T  \n",
       "19      0  1.599388     T  \n",
       "20      0  1.638997     T  \n",
       "21     20  1.658228     F  \n",
       "22      0  1.695616     T  \n",
       "23     60  1.713798     T  \n",
       "24      0  1.731656     F  \n",
       "25      0  1.766442     F  \n",
       "26     70  1.800058     T  \n",
       "27     20  1.816452     F  \n",
       "28     80  1.848455     T  \n",
       "29      0  1.894617     T  \n",
       "..    ...       ...   ...  \n",
       "67     10  2.962692     T  \n",
       "68      0  2.962692     T  \n",
       "69      5  2.972975     T  \n",
       "70     60  3.013081     T  \n",
       "71     25  3.037354     T  \n",
       "72     20  3.056357     F  \n",
       "73     90  3.075006     F  \n",
       "74     20  3.275256     T  \n",
       "75     50  3.337547     T  \n",
       "76     60  3.392829     T  \n",
       "77     10  3.435599     T  \n",
       "78     70  3.457893     T  \n",
       "79     50  3.513037     F  \n",
       "80     40  3.516013     T  \n",
       "81     60  3.530763     T  \n",
       "82     30  3.565298     T  \n",
       "83     70  3.570940     F  \n",
       "84     30  3.587677     T  \n",
       "85     60  3.630986     T  \n",
       "86      0  3.680091     T  \n",
       "87     30  3.712352     T  \n",
       "88     60  3.984344     T  \n",
       "89     75  3.993603     T  \n",
       "90      0  4.029806     T  \n",
       "91     15  4.129551     T  \n",
       "92     60  4.385147     T  \n",
       "93     40  4.684443     T  \n",
       "94     10  5.143124     F  \n",
       "95     80  5.477509     T  \n",
       "96     20  5.582932     F  \n",
       "\n",
       "[97 rows x 11 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.145456</td>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     lcavol    lweight        age       lbph        svi  \\\n",
       "count   97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    49.000000   1.350010   3.628943  63.865979   0.100356   0.216495   \n",
       "std     28.145456   1.178625   0.428411   7.445117   1.450807   0.413995   \n",
       "min      1.000000  -1.347074   2.374906  41.000000  -1.386294   0.000000   \n",
       "25%     25.000000   0.512824   3.375880  60.000000  -1.386294   0.000000   \n",
       "50%     49.000000   1.446919   3.623007  65.000000   0.300105   0.000000   \n",
       "75%     73.000000   2.127041   3.876396  68.000000   1.558145   0.000000   \n",
       "max     97.000000   3.821004   4.780383  79.000000   2.326302   1.000000   \n",
       "\n",
       "             lcp    gleason       pgg45       lpsa  \n",
       "count  97.000000  97.000000   97.000000  97.000000  \n",
       "mean   -0.179366   6.752577   24.381443   2.478387  \n",
       "std     1.398250   0.722134   28.204035   1.154329  \n",
       "min    -1.386294   6.000000    0.000000  -0.430783  \n",
       "25%    -1.386294   6.000000    0.000000   1.731656  \n",
       "50%    -0.798508   7.000000   15.000000   2.591516  \n",
       "75%     1.178655   7.000000   40.000000   3.056357  \n",
       "max     2.904165   9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Normalización de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de llevar la construcción de un modelo predictivo, es necesario normalizar los datos,\n",
    "pues se está trabajando con variables medidas en unidades y escalas diferentes. Al normalizar,\n",
    "es posible realizar comparaciones razonables entre ellas. Así, cada variable numérica se escala\n",
    "en el rango [0,1]. Para esta instancia en particular, los valores de *lpsa* se mantienen respecto al dataset original. También, se observa que la media de cada variable tiende a 0 y la varianza es muy cercana a 1. Para la normalización, se lleva a cabo el siguiente procedimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: F",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-45d80e49d12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpsa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpsa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    578\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    579\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                       force_all_finite)\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: F"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['lpsa'] = df['lpsa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Construcción de modelo de regresión lineal ordinaria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar el modelo, se ejecutan los siguientes pasos: <br> \n",
    "1. Primero, se separa el conjunto de datos en dos partes: La primera contiene solo las\n",
    "variables predictivas ($C_1$), mientras que la segunda, sólo la variable a predecir ($C_2$).<br> <br> \n",
    "2. En $C_1$ , se agrega una nueva variable, que representa el intercepto que será utilizado por\n",
    "cada registro para construir el modelo de regresión. <br> <br>\n",
    "3. Tanto $C_1$ como $C_2$ se subdividen en un conjunto que contiene registros que pertenecen\n",
    "al set de entrenamiento ($C_{11}$ y $C_{21}$) y en otro que agrupa los que pertenecen al set de prueba ($C_{21}$ y $C_{22}$ ). <br> <br>\n",
    "4. Finalmente, para implementar la regresión lineal, se entrega a la función correspondiente\n",
    "los conjuntos $C_{11}$ y $C_{21}$ como argumentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2fe6e5c23207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'intercept'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpsa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mistrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X = df_scaled.ix[: , :-1]\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['lpsa']\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 Pesos y Z-score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen los pesos, errores estándar y Z-score para cada variable del\n",
    "modelo elaborado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a7d5cbf770a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Pesos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Standard error of the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSEM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#A partir de lo anterior, se calculan los Z-score de cada variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "#Pesos\n",
    "weights = linreg.coef_\n",
    "#Error estandar\n",
    "SEM = np.asarray(Xtrain.std()) / np.sqrt(len(Xtrain))\n",
    "#A partir de lo anterior, se calculan los Z-score de cada variable\n",
    "Z_score = weights / SEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla 1 resume los valores obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <table style=\"width:100%\">\n",
    " <caption>Tabla 1: Peso, SEM y Z-score de cada variable del modelo LSS.</caption>\n",
    "  <tr>\n",
    "    <th>**Variable**</th>\n",
    "    <th>**Peso**</th>\n",
    "    <th>**Error Estándar (SEM)**</th>\n",
    "    <th>**Z-score**</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lcavol*</td>\n",
    "    <td>0.68</td>\n",
    "    <td>0.13</td>\n",
    "    <td>5.22</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lweight*</td>\n",
    "    <td>0.26</td>\n",
    "    <td>0.14</td>\n",
    "    <td>1.92</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lcavol*</td>\n",
    "    <td>-0.14</td>\n",
    "    <td>0.12</td>\n",
    "    <td>-1.14</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lbph*</td>\n",
    "    <td>0.21</td>\n",
    "    <td>0.12</td>\n",
    "    <td>1.69</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*svi*</td>\n",
    "    <td>0.30</td>\n",
    "    <td>0.12</td>\n",
    "    <td>2.44</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*lcp*</td>\n",
    "    <td>-0.29</td>\n",
    "    <td>0.12</td>\n",
    "    <td>-2.33</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*gleason*</td>\n",
    "    <td>-0.02</td>\n",
    "    <td>0.12</td>\n",
    "    <td>-0.18</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>*pgg45*</td>\n",
    "    <td>0.27</td>\n",
    "    <td>0.13</td>\n",
    "    <td>2.08</td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a estos resultados, las variables que presentan una mayor correlación con la\n",
    "variable a predecir son *lcavol*, *svi* y *lcp*. Si se utiliza un nivel de significancia del 5 %, entonces existe evidencia suficiente para afirmar que la variable **NO** presenta una fuerte relación con la respuesta si Z-score ∈ [-1.668, 1.668]. Ante esto, existe evidencia suficiente para afirmar que las variables *age* y *gleason* no están relacionadas con la variable a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6 Estimación de error de predicción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente, se calcula el error real del modelo (error cuadrático medio), obteniéndose\n",
    "MSE = 0.52."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-33611e0b0c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmse_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "print mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se evalúan los resultados obtenidos por medio del método cross validation.\n",
    "Se estudian dos casos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caso 1**: K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5a36453d8445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mk_fold1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmse_cv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "k_fold1 = cross_validation.KFold(len(Xm), 5)\n",
    "mse_cv1 = 0\n",
    "for k, (train, val) in enumerate(k_fold1):\n",
    "  linreg = lm.LinearRegression(fit_intercept = False)\n",
    "  linreg.fit(Xm[train], ym[train])\n",
    "  yhat_val = linreg.predict(Xm[val])\n",
    "  mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "  mse_cv1 += mse_fold\n",
    "mse_cv1 = mse_cv1 / 5\n",
    "print mse_cv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, para K = 5, se obtiene un error $e_1$ = 0.96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caso 2**: K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-202785ae37d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmse_cv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlinreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xm' is not defined"
     ]
    }
   ],
   "source": [
    "k_fold2 = cross_validation.KFold(len(Xm), 10)\n",
    "mse_cv2 = 0\n",
    "for k, (train, val) in enumerate(k_fold2):\n",
    "  linreg = lm.LinearRegression(fit_intercept = False)\n",
    "  linreg.fit(Xm[train], ym[train])\n",
    "  yhat_val = linreg.predict(Xm[val])\n",
    "  mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "  mse_cv2 += mse_fold\n",
    "mse_cv2 = mse_cv2 / 10\n",
    "print mse_cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, con K = 10, se obtiene un error $e_2$ = 0.76. <br>\n",
    "\n",
    "Se observa que para los casos 1 y 2, el error es considerablemente mayor respecto a MSE.\n",
    "Esto quiere decir que existe un alto nivel de dependencia del modelo respecto a los datos\n",
    "usados para construirlo. En otras palabras, el modelo está sobre ajustado (*overfitting*), por\n",
    "lo que entregará buenas predicciones para los casos pertenecientes al dataset original, pero\n",
    "no será el más apropiado si se desea predecir el valor de la variable de interés para casos de\n",
    "pacientes que no se encuentran dentro del conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7 Error de predicción por dato**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estudia la validez de suponer que los errores de predicción sobre los datos de entrenamiento siguen una distribución normal. Con la ejecución del siguiente código, se obtiene un gráfico que muestra el comportamiento de los errores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d472b4e3c3a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Se estima error de prediccion por cada dato de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myhat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mytrain_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mytrain_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Se genera grafico de errores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "#Se estima error de prediccion por cada dato de entrenamiento\n",
    "yhat_train = linreg.predict(Xtrain)\n",
    "ytrain_array = np.asarray(ytrain)\n",
    "error = yhat_train - ytrain_array\n",
    "#Se genera grafico de errores\n",
    "stats.probplot(error, dist='norm', plot=plt)\n",
    "plt.title('Siguen los errores de prediccion sobre el conjunto de entrenamiento una distribucion normal?')\n",
    "plt.ylabel('Error dato de entrenamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el conjunto de errores puede representarse mediante una recta, idea que\n",
    "se reafirma al notar que el coeficiente de correlación es $R^2$ = 0,9913. Como consecuencia de\n",
    "lo anterior, y de acuerdo con el marco teórico, es correcto señalar que los errores siguen una\n",
    "distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selección vía FSS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa *Forward Step-wise Selection* (FSS). Para agregar una variable al modelo, se utiliza como criterio el mínimo MSE. A continuación, se construye un gráfico con el error de entrenamiento y de pruebas de acuerdo en función de la cantidad de variables. Es pertinente señalar que FSS parte incluyendo el intercepto y luego empieza a agregar variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
